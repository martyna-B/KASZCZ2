---
title: "Sprawozdanie 2"
author: "Kaludia Jaworek, Martyna Bielec"
date: "`r Sys.Date()`"
output:
  pdf_document:
    fig_caption: yes
    number_sections: yes
    extra_dependencies: ["polski", "float"]
  word_document: default
---

```{r setup, include = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
knitr::knit_engines$set(python = reticulate::eng_python)
knitr::opts_chunk$set(pythonreticulate = FALSE)
```

```{r include = FALSE}
library(reticulate)
```

```{python include = FALSE}
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from scipy import stats, optimize
from statsmodels.tsa.stattools import pacf
from IPython.display import display
import statsmodels.api as sm

sns.set_style("darkgrid")
sns.set_palette(["steelblue", "red"]) 

def autocovariance_estimator(data, h):
    n = len(data)
    h = np.abs(h)
    new_first_data = data[h:]
    new_second_data = data[:n-h]
    mean_data = np.mean(data)
    
    output = (1/n)*sum((new_first_data - mean_data)*(new_second_data - mean_data))
    
    return output

def autocorrelation_estimator(data, h):
  
    data = np.array(data)
    autocovariance = autocovariance_estimator(data, h)
    variance = autocovariance_estimator(data, 0)
    
    return autocovariance/variance
```

# Wstęp

Dane, które poddamy analizie, dotyczą pogody w Londynie w latach 1979-2020. Pomiary były dokonywane codziennie w stacji pogodowej w pobliżu lotniska Heathrow. Zawierają informacje dotyczące m.in. zachmurzenia, nasłonecznienia, ciśnienia oraz temperatury. W sprawozdaniu zajmiemy się analizą maksymalnej temperatury. Sprawdzimy trend deterministyczny i dokonamy dekompozycji, a następnie sprawdzimy jaki szereg czasowy najlepiej modeluje zachowanie danych. Szereg będziemy oznaczać jako $\{X_t\}$.


 
```{python echo = FALSE, fig.cap = "\\label{wykres bez obrobki}Maksymalna temperatura w Londynie.", fig.pos = "H"}

weather_data = pd.read_csv("london_weather.csv")
max_temp_data = weather_data["max_temp"]
date_data = weather_data["date"]
correct_date = [pd.to_datetime(str(date), format='%Y%m%d') for date in date_data]
weather_data["correct_date"] = correct_date
plt.plot(correct_date, max_temp_data)
plt.xlabel("Czas")
plt.ylabel("Maksymalna temperatura")
```

Z wykresu [\ref{wykres bez obrobki}] odczytujemy, że obserwowane wartości wykazują się sezonowością, zgodnie z oczekiwaniami. 


# Przygotowanie danych do analizy

## Wartości brakujące i obserwacje odstające

W danych znajduje się sześć dni, dla których nie zmierzono maksymalnej temperatury. Są to: 05.02, 10.03, 06.05, 16.07, 10.08 oraz 08.10 z 2020 roku. Z tego powodu weźmiemy pod uwagę jedynie dane sprzed 2020 roku. 

```{python include = FALSE}
date_data = date_data[:-365]
max_temp_data = max_temp_data[:-365]
correct_date = correct_date[:-365]
```

Najwyższa zaobserwowana temperatura wyniosła $37.9 ^\circ$, a najniższa $-6.2^\circ$. Wartości są wiarygodne, skąd wnioskujemy, że dane nie zawierają błędów w pomiarach.

## Dekompozycja szeregu czasowego

### ACF oraz PACF dla surowych danych

ACF jest funkcją korelacji między dwoma obserwacjami z szeregu $\{X_t\}$, oddalonymi o $h$, gdzie $h \in \mathbf{Z}$, czyli $\mathrm{corr}(X_t, X_{t+h})$. Estymuje się ją w natępujący sposób:

$$\hat{\rho}(h) = \frac{\hat{\gamma}(h)}{\hat{\gamma}(0)},$$
gdzie $\hat{\gamma}(h)$ jest empiryczną funkcją autokowariancji, wyrażoną wzorem

$$\hat{\gamma}(h) = \frac{1}{n} \sum_{t=1}^{n - |h|} (x_{t+|h|} - \overline{x})(x_t - \overline{x}),$$

gdzie $x_1, x_2, \dots, x_n$ są realizacjami szeregu czasowego $X_t$, a $\overline{x} = \frac{1}{n}\sum_{i=1}^n x_i$.

Obliczamy ACF dla badanego szeregu czasowego, dla $h=0, 1, 2, \dots 20$.

```{python echo = FALSE, fig.cap = "\\label{fig:ACF bez obrobki 20}ACF dla surowych danych dla $h < 21$.", fig.pos = "H"}

H_20 = np.arange(21)
autocorr_20 = [autocorrelation_estimator(max_temp_data, h) for h in H_20]

plt.plot(H_20, autocorr_20)
plt.xlabel("$h$")
plt.ylabel("ACF")
```



```{python echo = FALSE, fig.cap = "\\label{fig:ACF bez obrobki 1000}ACF dla surowych danych dla $h < 1001$.", fig.pos = "H"}

#to pewnie się usunie

H_1000 = np.arange(1001)
autocorr_1000 = [autocorrelation_estimator(max_temp_data, h) for h in H_1000]

plt.plot(H_1000, autocorr_1000)
plt.xlabel("$h$")
plt.ylabel("ACF")
```

PACF jest funkcją częściowej autokorelacji. Służy do określenia bezpośredniej zależności między $X_t$ a $X_{t+h}$. Definiujemy ją w następujący sposób

$$\alpha(0)=1, \alpha(h) = \phi_{hh}, h \ge 1,$$
gdzie $\phi_{hh}$ jest ostatnią składową $\phi_h = \Gamma_h^{-1}\gamma_h,$ gdzie $\Gamma_h = [\gamma(i-j)]^h_{i,j=i}, \gamma_h = [\gamma(1), \gamma(2), \dots, \gamma(h)]'.$

PACF dla danych obliczymy z użyciem funkcji wbudowanej w języku programowania Python.

```{python echo = FALSE, fig.cap = "\\label{fig:PACF bez obrobki 20}PACF dla surowych danych dla $h < 21$.", fig.pos = "H"}

PACF_20 = pacf(max_temp_data, nlags=20)
plt.plot(np.arange(21), PACF_20)
plt.xlabel("$h$")
plt.ylabel("PACF")
```

```{python echo = FALSE, fig.cap = "\\label{fig:PACF bez obrobki 1000}PACF dla surowych danych dla $h < 1001$.", fig.pos = "H"}

PACF_1000 = pacf(max_temp_data, nlags=1000)
plt.plot(np.arange(1001), PACF_1000)
plt.xlabel("$h$")
plt.ylabel("PACF")
```

### Identyfikacja trendów deterministycznych

W danych widać trend liniowy i sezonowość dlatego spodziewamy się, że 

$$X_t = m(t) + s(t) + Y_t,$$
gdzie $m(t)$ to wielomian rzędu 1, $s(t)$ to funkcja okresowa, a ${Y_t}$ to szereg ARMA($p$, $q$).

```{python include = FALSE}
line_fit = np.polyfit(np.arange(len(correct_date)), max_temp_data, 1)
```

```{r nclude = FALSE}
line_fit <- py$line_fit
```

Do estymacji współczynników funkcji $m(t)$ i $s(t)$ wykorzystamy funkcje korzystajace z metody najmniejszych kwadratów zaimplementowane w języku Python. W ten sposób otrzymujemy, że 

$$m(t) \approx `r round(line_fit[1], 6)` t + `r round(line_fit[2], 2)`,$$
gdzie $t$ oznacza liczbę dni, które upłynęły od 1.01.1979r. Dodatni współczynnik kierunkowy prostej $m(t)$ wskazuje, że wraz z upływem czasu rosły maksymalne temperatury powietrza w Londynie. Po analizie wykresu [\ref{fig:dopasowana prosta}] możemy stwierdzić, że dopasowana prosta adekwatnie opisuje ten wzrost temperatur, więc zakładamy, że współczynniki zostały dobrane poprawnie.

```{python echo = FALSE, fig.cap = "\\label{fig:dopasowana prosta}Dopasowanie funkcji liniowej do danych.", fig.pos = "H"}
plt.plot(correct_date, max_temp_data, label = "Dane")
plt.plot(correct_date, np.polyval(line_fit, np.arange(len(correct_date))), label = "Dopasowana prosta")
plt.xlabel("Czas")
plt.ylabel("Maksymalna temperatura")
plt.legend()
```

Wykres [\ref{fig:bez trendu}] przedstawia dane po usunięciu liniowego trendu.

```{python echo = FALSE, fig.cap = "\\label{fig:bez trendu}Maksymalna temperatura w Londynie po usunięciu trendu liniowego.", fig.pos = "H"}
temp_without_trend = max_temp_data - np.polyval(line_fit, np.arange(len(correct_date)))
plt.plot(correct_date, temp_without_trend)
plt.xlabel("Czas")
plt.ylabel("Maksymalna temperatura")
```

```{python include = FALSE}
def my_sin(x, T, amplitude, phase):
    return np.sin(x * 2 * np.pi /T + phase) * amplitude

sin_fit = optimize.curve_fit(my_sin, np.arange(len(correct_date)), temp_without_trend, p0 = [365, 20, 0])[0]
```

```{r include = FALSE}
sin_fit <- py$sin_fit
```

Po estymacji współczynników funkcji $s(t)$ otrzymujemy

$$s(t) \approx `r round(sin_fit[2], 2)`\sin \left( \frac{2\pi t}{`r round(sin_fit[1], 2)`} + `r round(sin_fit[3], 2)`\right),$$
gdzie $t$ podobnie jak poprzednio oznacza liczbę dni, które upłynęły od 1.01.1979r. Po analizie wykresu [\ref{fig:dopasowany sinus}] możemy stwierdzić, że funkcja została poprawnie dobrana. Dane po odjęciu wartości funkcji $m(t)$ i $s(t)$ zostały przedstawione na wykresie [\ref{fig:bez sezonowości}] i wyglądają na losowe, co sugeruje, że całkowicie pozbyliśmy się z nich trendu i sezonowości.

```{python echo = FALSE, fig.cap = "\\label{fig:dopasowany sinus}Dopasowanie funkcji okresowej do danych.", fig.pos = "H"}
fitted_sin = my_sin(np.arange(len(correct_date)), *sin_fit)
plt.plot(correct_date, temp_without_trend, label = "Dane")
plt.plot(correct_date, fitted_sin, label = "Dopasowana funkcja okresowa")
plt.xlabel("Czas")
plt.ylabel("Maksymalna temperatura")
plt.legend()
```

```{python echo = FALSE, fig.cap = "\\label{fig:bez sezonowości}Maksymalna temperatura w Londynie po usunięciu trendu liniowego i sezonowości.", fig.pos = "H"}
temp_without_seasonality = temp_without_trend - fitted_sin
plt.plot(correct_date, temp_without_seasonality)
plt.xlabel("Czas")
plt.ylabel("Maksymalna temperatura")
```

### ACF oraz PACF dla danych po usunięciu trendów deterministycznych

```{python echo = FALSE, fig.cap = "\\label{fig:ACF po obrobce 20}ACF dla danych po usunięciu trendów deterministycznych dla $h < 21$.", fig.pos = "H"}

autocorr_20_after = [autocorrelation_estimator(temp_without_seasonality, h) for h in H_20]

plt.plot(H_20, autocorr_20_after)
plt.xlabel("$h$")
plt.ylabel("ACF")
```

```{python echo = FALSE, fig.cap = "\\label{fig:ACF po obrobce 1000}ACF dla danych po usunięciu trendów deterministycznych dla $h < 1001$.", fig.pos = "H"}

autocorr_1000_after = [autocorrelation_estimator(temp_without_seasonality, h) for h in H_1000]

plt.plot(H_1000, autocorr_1000_after)
plt.xlabel("$h$")
plt.ylabel("ACF")
```

```{python echo = FALSE, fig.cap = "\\label{fig:PACF po obrobce 20}PACF dla danych po usunięciu trendów deterministycznych dla $h < 21$.", fig.pos = "H"}

PACF_20_after = pacf(temp_without_seasonality, nlags=20)
plt.plot(np.arange(21), PACF_20_after)
plt.xlabel("$h$")
plt.ylabel("PACF")
```

```{python echo = FALSE, fig.cap = "\\label{fig:PACF po obrobce 1000}PACF dla danych po usunięciu trendów deterministycznych dla $h < 1001$.", fig.pos = "H"}

PACF_1000_after = pacf(temp_without_seasonality, nlags=1000)
plt.plot(np.arange(1001), PACF_1000_after)
plt.xlabel("$h$")
plt.ylabel("PACF")
```

## Modelowanie danych przy pomocy ARMA.

### Dobranie rzędu modelu.

Chcemy zamodelować dane szeregiem czasowym ARMA($p$, $q$). W tym celu musimy wyznaczyć optymalne wartości $p$ i $q$. Posłużymy się kryterium informacyjny Akaikego.

Wyliczymy wartość AIC dla parametrów $p \in \{0, 1, \dots, 9\}$ oraz $q \in \{0, 1, \dots, 9\}$.

```{python echo = FALSE}
pq_df = pd.read_csv("pq.csv")

def color_blue(val):
    color = 'blue' if val == 68666.32 else 'black'
    return 'color: % s' % color
  
pq_df.style.applymap(color_blue)

#do zmiany na ładniejszą tabelę  
display(pq_df)
```

AIC przyjmuje najmniejszą wartość dla $p=9, q=0$. Przyjmujemy więc, że badany szereg czasowy $\{X_t\}$ jest ARMA($9$, $0$), czyli AR($9$).

### Estymacja parametrów modelu.

Badany szereg czasowy $\{X_t\}$ jest postaci:

$$X_t - \phi_1 X_{t-1} - \phi_2 X_{t-2} - \dots - \phi_9 X_{t-9} = Z_t,$$
gdzie $Z_t \sim WN(0, \sigma^2).$ Wyestymujemy parametry $\phi_i$, korzystając z metody Yule-Walkera.

```{python echo = FALSE}
phi, sigma = sm.regression.yule_walker(max_temp_data, order=9)
```

```{=latex}

\begin{table}[H]
\label{tabela phi}
\begin{center}
\begin{tabular}{|l|l|ll}
\hline
\textbf{$\phi_1$} & 0.7588 & \multicolumn{1}{l|}{\textbf{$\phi_6$}} & \multicolumn{1}{l|}{0.0229} \\ \hline
\textbf{$\phi_2$} & 0.0217 & \multicolumn{1}{l|}{\textbf{$\phi_7$}} & \multicolumn{1}{l|}{0.0255} \\ \hline
\textbf{$\phi_3$} & 0.0130 & \multicolumn{1}{l|}{\textbf{$\phi_8$}} & \multicolumn{1}{l|}{0.0018} \\ \hline
\textbf{$\phi_4$} & 0.0308 & \multicolumn{1}{l|}{\textbf{$\phi_9$}} & \multicolumn{1}{l|}{0.0556} \\ \hline
\textbf{$\phi_5$} & 0.0332 &                                        &                             \\ \cline{1-2}
\end{tabular}
\end{center}
\caption{Wartości parametrów $\phi_i$.}
\end{table}

```
